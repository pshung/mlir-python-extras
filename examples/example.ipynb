{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlir._mlir_libs._mlir.ir.Module'>\n",
      "module {\n",
      "  func.func @matmul(%arg0: tensor<3x3xf32>, %arg1: tensor<3x3xf32>, %arg2: tensor<3x3xf32>) -> tensor<3x3xf32> {\n",
      "    %0 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%arg0, %arg1 : tensor<3x3xf32>, tensor<3x3xf32>) outs(%arg2 : tensor<3x3xf32>) -> tensor<3x3xf32>\n",
      "    return %0 : tensor<3x3xf32>\n",
      "  }\n",
      "}\n",
      "\n",
      "INVOKE matmul\n",
      "Results: [[3. 3. 3.]\n",
      " [3. 3. 3.]\n",
      " [3. 3. 3.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3139033/722318355.py:66: UserWarning: Making copy of unaligned VmModule buffer. It is recommended to make this deterministic by calling `copy_buffer` to always make a copy or `mmap` to efficiently load from a file. This warning can be silenced by adding `warn_if_copy=False` to `from_buffer`\n",
      "  vm_module = ireert.VmModule.from_flatbuffer(ctx.instance, compiled_flatbuffer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/nick/work/MLIR/build/tools/mlir/python_packages/mlir_core')\n",
    "sys.path.append('/home/nick/work/mlir_nelli')\n",
    "sys.path.append('/home/nick/work/mlir_nelli/.venv/lib/python3.11/site-packages')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mlir.extras.types as T\n",
    "from mlir.extras.ast.canonicalize import canonicalize\n",
    "from mlir.extras.context import ContextManager\n",
    "from mlir.extras.dialects.ext.arith import constant\n",
    "from mlir.extras.dialects.ext.memref import S\n",
    "from mlir.extras.dialects.ext.func import toMLIRFunc\n",
    "from mlir.extras.dialects.ext.scf import canonicalizer as scf_canonicalizer, range_ as range\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n",
    "from mlir.ir import StridedLayoutAttr\n",
    "from mlir.extras.dialects.ext import linalg\n",
    "from mlir.dialects.transform.extras import named_sequence\n",
    "from mlir.dialects import pdl\n",
    "from mlir.dialects.transform.structured import structured_match\n",
    "from mlir.dialects.transform.loop import loop_unroll\n",
    "from mlir.ir import UnitAttr\n",
    "from mlir.dialects.transform import get_parent_op, print_, any_op_t\n",
    "from mlir.dialects.builtin import module\n",
    "from mlir.extras.dialects.ext.transform import (\n",
    "    match,\n",
    "    tile,\n",
    "    tile_to_scf_forall,\n",
    ")\n",
    "# import IREE binding\n",
    "from iree import runtime as ireert\n",
    "from iree.compiler import compile_str\n",
    "\n",
    "import re\n",
    "\n",
    "# create MLIR context\n",
    "CM = ContextManager()\n",
    "Ctx = CM.__enter__()\n",
    "backend = LLVMJITBackend()\n",
    "\n",
    "K = 1024\n",
    "\n",
    "@toMLIRFunc(emit=True)\n",
    "@canonicalize(using=scf_canonicalizer)\n",
    "def matmul(\n",
    "    arg0: T.tensor(K, K, T.f32()),\n",
    "    arg1: T.tensor(K, K, T.f32()),\n",
    "    out : T.tensor(K, K, T.f32()),\n",
    "):\n",
    "    return linalg.matmul(arg0, arg1, out)\n",
    "\n",
    "\n",
    "module = str(run_pipeline(Ctx.module, Pipeline().cse()))\n",
    "\n",
    "# dirty work to rename module\n",
    "pattern = re.compile(r'(module\\s*\\{)')\n",
    "module= re.sub(pattern, r'module @arithmetic {', module)\n",
    "\n",
    "\n",
    "\n",
    "compiled_flatbuffer = compile_str(module, target_backends=[\"vmvx\"])\n",
    "config = ireert.Config(\"local-task\")\n",
    "ctx = ireert.SystemContext(config=config)\n",
    "vm_module = ireert.VmModule.from_flatbuffer(ctx.instance, compiled_flatbuffer)\n",
    "ctx.add_vm_module(vm_module)\n",
    "\n",
    "# Invoke the function and print the result.\n",
    "print(\"INVOKE matmul\")\n",
    "arg0 = np.ones((K, K), dtype=np.float32)\n",
    "arg1 = np.ones((K, K), dtype=np.float32)\n",
    "init = np.zeros((K, K), dtype=np.float32)\n",
    "f = ctx.modules.arithmetic[\"matmul\"]\n",
    "result = f(arg0, arg1, init).to_host()\n",
    "print(\"Results:\", result)\n",
    "assert np.array_equal(np.dot(arg0, arg1), result)\n",
    "CM.__exit__(None, None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module {\n",
      "  func.func @matmul(%arg0: tensor<1024x1024xf32>, %arg1: tensor<1024x1024xf32>, %arg2: tensor<1024x1024xf32>) -> tensor<1024x1024xf32> attributes {llvm.emit_c_interface} {\n",
      "    %0 = linalg.matmul {cast = #linalg.type_fn<cast_signed>} ins(%arg0, %arg1 : tensor<1024x1024xf32>, tensor<1024x1024xf32>) outs(%arg2 : tensor<1024x1024xf32>) -> tensor<1024x1024xf32>\n",
      "    return %0 : tensor<1024x1024xf32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "MlirCompilerError",
     "evalue": "Lowering IR failed with the following diagnostics:\n\n********************************************************************************\nFailure while executing pass pipeline:\nerror: \"-\":3:10: expected add/mul op in the body\nnote: \"-\":3:10: see current operation: \n\"linalg.matmul\"(%8, %17, %52) <{cast = #linalg.type_fn<cast_signed>, operandSegmentSizes = array<i32: 2, 1>}> ({\n^bb0(%arg21: f32, %arg22: f32, %arg23: f32):\n%64 = \"llvm.fmul\"(%arg21, %arg22) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n%65 = \"llvm.fadd\"(%arg23, %64) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n\"linalg.yield\"(%65) : (f32) -> ()\n}) {linalg.memoized_indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>]} : (memref<1024x1024xf32>, memref<1024x1024xf32>, memref<1024x1024xf32>) -> ()\n********************************************************************************\n\nFor developers, the error can be reproduced with:\n$ mlir-opt -mlir-print-ir-after-all -mlir-disable-threading -pass-pipeline='builtin.module(func.func(scf-bufferize,empty-tensor-to-alloc-tensor,linalg-bufferize),func-bufferize,arith-bufferize,func.func(tensor-bufferize,finalizing-bufferize,buffer-deallocation),cse,func.func(lower-affine,arith-expand,convert-math-to-llvm),convert-math-to-libm,expand-strided-metadata,finalize-memref-to-llvm,convert-scf-to-cf,convert-cf-to-llvm,cse,lower-affine,convert-func-to-llvm,canonicalize,convert-openmp-to-llvm,cse,reconcile-unrealized-casts)' /tmp/UnnammedModule.mlir\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMLIRError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/work/mlir_nelli/mlir/extras/runtime/passes.py:3504\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(module, pipeline, description, enable_ir_printing, print_pipeline, verify)\u001b[0m\n\u001b[1;32m   3502\u001b[0m             pm\u001b[38;5;241m.\u001b[39menable_ir_printing()\n\u001b[0;32m-> 3504\u001b[0m         \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mMLIRError\u001b[0m: Failure while executing pass pipeline:\nerror: \"-\":3:10: expected add/mul op in the body\n note: \"-\":3:10: see current operation: \n  \"linalg.matmul\"(%8, %17, %52) <{cast = #linalg.type_fn<cast_signed>, operandSegmentSizes = array<i32: 2, 1>}> ({\n  ^bb0(%arg21: f32, %arg22: f32, %arg23: f32):\n    %64 = \"llvm.fmul\"(%arg21, %arg22) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n    %65 = \"llvm.fadd\"(%arg23, %64) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n    \"linalg.yield\"(%65) : (f32) -> ()\n  }) {linalg.memoized_indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>]} : (memref<1024x1024xf32>, memref<1024x1024xf32>, memref<1024x1024xf32>) -> ()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlirCompilerError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdialects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     match,\n\u001b[1;32m     11\u001b[0m     tile,\n\u001b[1;32m     12\u001b[0m     tile_to_scf_forall,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#@module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#def mod():\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#    @named_sequence(\"__transform_main\", [any_op_t()], [])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#module = run_pipeline(Ctx.module, Pipeline().transform_interpreter().canonicalize())\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#pipeline=Pipeline().convert_linalg_to_loops(),\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#pipeline=Pipeline().convert_linalg_to_std(),\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbufferize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower_to_llvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_kernel_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_return_consumer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#print(Ctx.module)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#invoker = backend.load(module)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#A = np.random.randint(0, 10, (K, K)).astype(np.float32)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#invoker.memfoo_capi_wrapper(AA, BB, CC)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#assert np.array_equal(A + B, C)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m CM\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/mlir_nelli/mlir/extras/runtime/refbackend.py:276\u001b[0m, in \u001b[0;36mLLVMJITBackend.compile\u001b[0;34m(self, module, pipeline, kernel_name, enable_ir_printing, generate_kernel_wrapper, generate_return_consumer, verify)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto-llvm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pipeline \u001b[38;5;129;01mor\u001b[39;00m generate_kernel_wrapper:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_c_api(\n\u001b[1;32m    273\u001b[0m         module, kernel_name, generate_kernel_wrapper, generate_return_consumer\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLowering IR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_ir_printing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_ir_printing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/mlir_nelli/mlir/extras/runtime/passes.py:3524\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(module, pipeline, description, enable_ir_printing, print_pipeline, verify)\u001b[0m\n\u001b[1;32m   3513\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with the following diagnostics:\u001b[39m\n\u001b[1;32m   3515\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3521\u001b[0m \u001b[38;5;124m        $ mlir-opt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdebug_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -pass-pipeline=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m   3522\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   3523\u001b[0m     trimmed_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mlstrip() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m message\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m-> 3524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlirCompilerError(trimmed_message)\n\u001b[1;32m   3525\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3526\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m original_stderr\n",
      "\u001b[0;31mMlirCompilerError\u001b[0m: Lowering IR failed with the following diagnostics:\n\n********************************************************************************\nFailure while executing pass pipeline:\nerror: \"-\":3:10: expected add/mul op in the body\nnote: \"-\":3:10: see current operation: \n\"linalg.matmul\"(%8, %17, %52) <{cast = #linalg.type_fn<cast_signed>, operandSegmentSizes = array<i32: 2, 1>}> ({\n^bb0(%arg21: f32, %arg22: f32, %arg23: f32):\n%64 = \"llvm.fmul\"(%arg21, %arg22) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n%65 = \"llvm.fadd\"(%arg23, %64) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32\n\"linalg.yield\"(%65) : (f32) -> ()\n}) {linalg.memoized_indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>]} : (memref<1024x1024xf32>, memref<1024x1024xf32>, memref<1024x1024xf32>) -> ()\n********************************************************************************\n\nFor developers, the error can be reproduced with:\n$ mlir-opt -mlir-print-ir-after-all -mlir-disable-threading -pass-pipeline='builtin.module(func.func(scf-bufferize,empty-tensor-to-alloc-tensor,linalg-bufferize),func-bufferize,arith-bufferize,func.func(tensor-bufferize,finalizing-bufferize,buffer-deallocation),cse,func.func(lower-affine,arith-expand,convert-math-to-llvm),convert-math-to-libm,expand-strided-metadata,finalize-memref-to-llvm,convert-scf-to-cf,convert-cf-to-llvm,cse,lower-affine,convert-func-to-llvm,canonicalize,convert-openmp-to-llvm,cse,reconcile-unrealized-casts)' /tmp/UnnammedModule.mlir\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#@module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "#def mod():\n",
    "#    @named_sequence(\"__transform_main\", [any_op_t()], [])\n",
    "#    def sched(target):\n",
    "#        m = match(target, [\"linalg.matmul\"])\n",
    "#       tiled_linalg_op, loops = tile(m, sizes=[8, 32])\n",
    "\n",
    "#module = run_pipeline(Ctx.module, Pipeline().transform_interpreter().canonicalize())\n",
    "#print(Ctx.module)\n",
    "#invoker = backend.load(module)\n",
    "#A = np.random.randint(0, 10, (K, K)).astype(np.float32)\n",
    "#AA = ctypes.pointer(ctypes.pointer(get_ranked_memref_descriptor(A)))\n",
    "#B = np.random.randint(0, 10, (K, K)).astype(np.float32)\n",
    "#BB = ctypes.pointer(ctypes.pointer(get_ranked_memref_descriptor(B)))\n",
    "#C = np.zeros((K, K)).astype(np.float32)\n",
    "#CC = ctypes.pointer(ctypes.pointer(get_ranked_memref_descriptor(C)))\n",
    "\n",
    "#invoker.memfoo_capi_wrapper(AA, BB, CC)\n",
    "#assert np.array_equal(A + B, C)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
